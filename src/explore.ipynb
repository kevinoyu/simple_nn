{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grad_val import GradTensor\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 3\n",
    "x_vals = np.array([random.random() for _ in range(model_size)])\n",
    "param_vals = np.array([random.random() for _ in range(model_size)])\n",
    "x = np.array([GradTensor(r) for r in x_vals])\n",
    "params = np.array([GradTensor(r) for r in param_vals])\n",
    "\n",
    "out = x * params\n",
    "\n",
    "final = np.sum(out)\n",
    "\n",
    "final.backward()\n",
    "final.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 2.335 after 0 iters\n",
      "MSE Loss: 2.034 after 25 iters\n",
      "MSE Loss: 1.826 after 50 iters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f02f0304920>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kevin/anaconda3/envs/dev/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 1.678 after 75 iters\n",
      "MSE Loss: 1.566 after 100 iters\n"
     ]
    }
   ],
   "source": [
    "from simple_net import *\n",
    "from optimizer import GDOptimizer\n",
    "from loss import MSELoss\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_ITER = 100\n",
    "\n",
    "y_true = np.array([GradVal(random()) for _ in range(BATCH_SIZE)])\n",
    "x = np.array([[GradVal(random()) for _ in range(8)] for _ in range(BATCH_SIZE)])\n",
    "\n",
    "pipeline = [SimpleLinearLayer(8, 16), SimpleReluLayer(), SimpleLinearLayer(16, 8), SimpleReluLayer(), SimpleLinearLayer(8, 1)]\n",
    "model = Model(pipeline=pipeline)\n",
    "optimizer = GDOptimizer(model.parameters(), lr=1e-4)\n",
    "mse = MSELoss()\n",
    "\n",
    "for i in range(MAX_ITER+1):\n",
    "    y_pred = model.forward(x)\n",
    "    loss = mse.loss(y_pred=y_pred, y_true=y_true)\n",
    "    loss.backward()\n",
    "    optimizer.optimize()\n",
    "    loss.zero_grad()\n",
    "    if i % 25 == 0:\n",
    "        print(f\"MSE Loss: {loss.val:.3f} after {i} iters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: [22.01774708] after 0 iters\n",
      "MSE Loss: [16.53186919] after 25 iters\n",
      "MSE Loss: [6.55472266] after 50 iters\n",
      "MSE Loss: [0.81047027] after 75 iters\n"
     ]
    }
   ],
   "source": [
    "from vector_net import *\n",
    "from optimizer import GDOptimizer\n",
    "from loss import MSELoss\n",
    "from simple_net import Model\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_ITER = 100\n",
    "\n",
    "y_true = GradVector(np.random.rand(BATCH_SIZE, 1))\n",
    "x = GradVector(np.random.rand(BATCH_SIZE, 8))\n",
    "\n",
    "pipeline = [VectorLinearLayer(8, 16), VectorReluLayer(), VectorLinearLayer(16, 8), VectorReluLayer(), VectorLinearLayer(8, 1)]\n",
    "model = Model(pipeline=pipeline)\n",
    "optimizer = GDOptimizer(model.parameters(), lr=1e-5)\n",
    "mse = MSELoss()\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    y_pred = model.forward(x)\n",
    "    loss = mse.loss(y_pred=y_pred, y_true=y_true)\n",
    "    loss.backward()\n",
    "    optimizer.optimize()\n",
    "    loss.zero_grad()\n",
    "    if i % 25 == 0:\n",
    "        print(f\"MSE Loss: {loss.val[0]} after {i} iters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_net import *\n",
    "from optimizer import GDOptimizer\n",
    "from loss import MSELoss\n",
    "from simple_net import Model\n",
    "import torch\n",
    "import numpy as np\n",
    "from grad_vector import GradVector\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "MAX_ITER = 100\n",
    "\n",
    "mse = MSELoss()\n",
    "\n",
    "actual = np.random.rand(BATCH_SIZE, 1)\n",
    "x = np.random.rand(BATCH_SIZE, 8)\n",
    "layer1 = VectorLinearLayer(8, 16)\n",
    "layer2 = VectorLinearLayer(16, 1)\n",
    "\n",
    "t_actual = torch.tensor(actual, requires_grad=True)\n",
    "data = torch.tensor(x, requires_grad=True)\n",
    "\n",
    "weights1 = torch.tensor(layer1.weights.val, requires_grad=True)\n",
    "weights2 = torch.tensor(layer2.weights.val, requires_grad=True)\n",
    "bias1 = torch.tensor(layer1.bias.val, requires_grad=True)\n",
    "bias2 = torch.tensor(layer2.bias.val, requires_grad=True)\n",
    "\n",
    "res = data @ weights1 + bias1\n",
    "res = res @ weights2 + bias2\n",
    "torch_mse = mse.loss(res, t_actual)\n",
    "torch_mse.backward()\n",
    "\n",
    "res_gv = layer1(GradVector(x))\n",
    "res_gv = layer2(res_gv)\n",
    "gv_mse = mse.loss(res_gv, GradVector(actual))\n",
    "gv_mse.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1.grad.allclose(torch.tensor(layer1.weights.gradient) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias1.grad.allclose(torch.tensor(layer1.bias.gradient) * 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
