{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grad_val import GradTensor\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 3\n",
    "x_vals = np.array([random.random() for _ in range(model_size)])\n",
    "param_vals = np.array([random.random() for _ in range(model_size)])\n",
    "x = np.array([GradTensor(r) for r in x_vals])\n",
    "params = np.array([GradTensor(r) for r in param_vals])\n",
    "\n",
    "out = x * params\n",
    "\n",
    "final = np.sum(out)\n",
    "\n",
    "final.backward()\n",
    "final.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 2.454 after 0 iters\n",
      "MSE Loss: 1.870 after 25 iters\n",
      "MSE Loss: 1.481 after 50 iters\n",
      "MSE Loss: 1.218 after 75 iters\n",
      "MSE Loss: 1.039 after 100 iters\n"
     ]
    }
   ],
   "source": [
    "from simple_net import *\n",
    "from optimizer import GDOptimizer\n",
    "from loss import MSELoss\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_ITER = 100\n",
    "\n",
    "y_true = np.array([GradVal(random()) for _ in range(BATCH_SIZE)])\n",
    "x = np.array([[GradVal(random()) for _ in range(8)] for _ in range(BATCH_SIZE)])\n",
    "\n",
    "pipeline = [SimpleLinearLayer(8, 16), SimpleReluLayer(), SimpleLinearLayer(16, 8), SimpleReluLayer(), SimpleLinearLayer(8, 1)]\n",
    "model = Model(pipeline=pipeline)\n",
    "optimizer = GDOptimizer(model.parameters(), lr=1e-4)\n",
    "mse = MSELoss()\n",
    "\n",
    "for i in range(MAX_ITER+1):\n",
    "    y_pred = model.forward(x)\n",
    "    loss = mse.loss(y_pred=y_pred, y_true=y_true)\n",
    "    loss.backward()\n",
    "    optimizer.optimize()\n",
    "    loss.zero_grad()\n",
    "    if i % 25 == 0:\n",
    "        print(f\"MSE Loss: {loss.val:.3f} after {i} iters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (32,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse\u001b[38;5;241m.\u001b[39mloss(y_pred\u001b[38;5;241m=\u001b[39my_pred, y_true\u001b[38;5;241m=\u001b[39my_true)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/fun/simple_nn/src/grad_vector.py:134\u001b[0m, in \u001b[0;36mGradVector.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vertex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(order):\n\u001b[0;32m--> 134\u001b[0m     \u001b[43mvertex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_back\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fun/simple_nn/src/grad_vector.py:38\u001b[0m, in \u001b[0;36mGradVector.__add__.<locals>._back_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_back_closure\u001b[39m():\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_tensor\u001b[38;5;241m.\u001b[39mgradient \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (32,1)"
     ]
    }
   ],
   "source": [
    "from vector_net import *\n",
    "from optimizer import GDOptimizer\n",
    "from loss import MSELoss\n",
    "from simple_net import Model\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_ITER = 100\n",
    "\n",
    "y_true = GradVector(np.random.rand(BATCH_SIZE, 1))\n",
    "x = GradVector(np.random.rand(BATCH_SIZE, 8))\n",
    "\n",
    "pipeline = [VectorLinearLayer(8, 16), VectorReluLayer(), VectorLinearLayer(16, 8), VectorReluLayer(), VectorLinearLayer(8, 1)]\n",
    "model = Model(pipeline=pipeline)\n",
    "optimizer = GDOptimizer(model.parameters(), lr=1e-4)\n",
    "mse = MSELoss()\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    y_pred = model.forward(x)\n",
    "    loss = mse.loss(y_pred=y_pred, y_true=y_true)\n",
    "    loss.backward()\n",
    "    optimizer.optimize()\n",
    "    loss.zero_grad()\n",
    "    if i % 25 == 0:\n",
    "        print(f\"MSE Loss: {loss.val:.3f} after {i} iters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
